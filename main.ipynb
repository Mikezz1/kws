{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lhrn5O-qUYZ"
      },
      "source": [
        "# Import and misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "meO-Mp9jiAFC"
      },
      "outputs": [],
      "source": [
        "# Instal latest torch and torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YeWu4q233X55"
      },
      "outputs": [],
      "source": [
        "# !pip install -qq --upgrade torch\n",
        "# !pip install -qq --upgrade torchaudio\n",
        "# !pip install thop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bbUpoArCqUYa"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Union, List, Callable, Optional\n",
        "from tqdm import tqdm\n",
        "from itertools import islice\n",
        "import pathlib\n",
        "import dataclasses\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import distributions\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import torchaudio\n",
        "from IPython import display as display_\n",
        "\n",
        "from collections import defaultdict\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Import models\n",
        "from models.blocks  import *\n",
        "from models.crnn_base import *\n",
        "from models.crnn_ds_small import *\n",
        "from models.crnn_base_streaming import *\n",
        "\n",
        "\n",
        "# Import functions from seminar\n",
        "from src.dataset import *\n",
        "from src.utils import *\n",
        "from src.trainer import  *\n",
        "from src.eval import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BXVWw2bRGKtO"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int):\n",
        "    \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "SEED = 42\n",
        "\n",
        "seed_everything(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8PdhApeEh9pH"
      },
      "outputs": [],
      "source": [
        "@dataclasses.dataclass\n",
        "class TaskConfig:\n",
        "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
        "    batch_size: int = 128\n",
        "    learning_rate: float = 4e-4\n",
        "    weight_decay: float = 1e-5\n",
        "    num_epochs: int = 30\n",
        "    n_mels: int = 40\n",
        "    cnn_out_channels: int = 8\n",
        "    kernel_size: Tuple[int, int] = (5, 20)\n",
        "    stride: Tuple[int, int] = (2, 8)\n",
        "    hidden_size: int = 32\n",
        "    gru_num_layers: int = 2\n",
        "    bidirectional: bool = False\n",
        "    num_classes: int = 2\n",
        "    sample_rate: int = 16000\n",
        "    temperature:int =  20\n",
        "    alpha:float = 0.6\n",
        "    gamma:float = 0.01\n",
        "    device: torch.device = torch.device(\n",
        "        'cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA1gPmE1h9pI"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2N8zcx9MF1X",
        "outputId": "24ad4b13-0cda-4509-9e20-ee251e9ea3b9"
      },
      "outputs": [],
      "source": [
        "# !wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz -O speech_commands_v0.01.tar.gz\n",
        "# !mkdir speech_commands && tar -C speech_commands -xvzf speech_commands_v0.01.tar.gz 1> log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-1rVkT81Pk90"
      },
      "outputs": [],
      "source": [
        "dataset = SpeechCommandDataset(\n",
        "    path2dir='speech_commands', keywords=TaskConfig.keyword\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUxfDJw1qUYi"
      },
      "source": [
        "### Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ClWThxyYh9pM"
      },
      "outputs": [],
      "source": [
        "indexes = pd.Series(np.arange(len(dataset))).sample(frac=1, random_state=SEED, replace=False).values\n",
        "train_indexes = indexes[:int(len(dataset) * 0.8)]\n",
        "val_indexes = indexes[int(len(dataset) * 0.8):]\n",
        "\n",
        "train_df = dataset.csv.iloc[train_indexes].reset_index(drop=True)\n",
        "val_df = dataset.csv.iloc[val_indexes].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PDPLht5fqUYe"
      },
      "outputs": [],
      "source": [
        "# Sample is a dict of utt, word and label\n",
        "train_set = SpeechCommandDataset(csv=train_df, transform=AugsCreation())\n",
        "val_set = SpeechCommandDataset(csv=val_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vbPDqd6qUYj"
      },
      "source": [
        "### Sampler for oversampling:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UM8gLmHeqUYj"
      },
      "outputs": [],
      "source": [
        "train_sampler = get_sampler(train_set.csv['label'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8G9xPRVqUYk"
      },
      "source": [
        "###  Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6wGBMcQiqUYk"
      },
      "outputs": [],
      "source": [
        "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n",
        "                          shuffle=False, collate_fn=Collator(),\n",
        "                          sampler=train_sampler,\n",
        "                          num_workers=0, pin_memory=True)\n",
        "\n",
        "val_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n",
        "                        shuffle=False, collate_fn=Collator(),\n",
        "                        num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTlsn6cpqUYk"
      },
      "source": [
        "### Creating MelSpecs on GPU for speeeed: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Pqkz4_gn8BiF"
      },
      "outputs": [],
      "source": [
        "melspec_train = LogMelspec(is_train=True, config=TaskConfig)\n",
        "melspec_val = LogMelspec(is_train=False, config=TaskConfig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PpyvKwp0k3IU"
      },
      "outputs": [],
      "source": [
        "history = defaultdict(list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSNW-nZCJ4Q0"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8sVpHNoocgA",
        "outputId": "649147f5-c4d3-437d-d0e7-b2ccfbd2cac3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRNN(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
            "    (1): Flatten(start_dim=1, end_dim=2)\n",
            "  )\n",
            "  (gru): GRU(144, 32, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (attention): Attention(\n",
            "    (energy): Sequential(\n",
            "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=32, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "config = TaskConfig(hidden_size=32, num_epochs=20)\n",
        "model = CRNN(config).to(config.device)\n",
        "\n",
        "opt = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config.learning_rate,\n",
        "    weight_decay=config.weight_decay\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zedXm9dmINAE"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "\n",
        "def calc_params(module):\n",
        "  return sum([p.numel() for p in module.parameters()])\n",
        "\n",
        "def get_size_in_megabytes(model):\n",
        "    # https://pytorch.org/tutorials/recipes/recipes/dynamic_quantization.html#look-at-model-size\n",
        "    with tempfile.TemporaryFile() as f:\n",
        "        torch.save(model.state_dict(), f)\n",
        "        size = f.tell() / 2**20\n",
        "    return size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFd9IuoIXUAI",
        "outputId": "e9ea0003-dc0f-4eb7-ecfd-500e99fdef26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('', 25387),\n",
              " ('conv', 808),\n",
              " ('conv.0', 808),\n",
              " ('conv.1', 0),\n",
              " ('gru', 23424),\n",
              " ('attention', 1089),\n",
              " ('attention.energy', 1089),\n",
              " ('attention.energy.0', 1056),\n",
              " ('attention.energy.1', 0),\n",
              " ('attention.energy.2', 33),\n",
              " ('classifier', 66)]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[(module_name, calc_params(module)) for module_name, module in model.named_modules()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0z4ZBubZycE4"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load('model.pth').state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "32oooz4lqUYo",
        "outputId": "fbb37e39-8903-4417-9317-fc1b751d3f24",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "#TRAIN\n",
        "\n",
        "# for n in range(config.num_epochs):\n",
        "\n",
        "#     train_epoch(model, opt, train_loader,\n",
        "#                 melspec_train, config.device)\n",
        "\n",
        "#     au_fa_fr = validation(model, val_loader,\n",
        "#                           melspec_val, config.device)\n",
        "#     history['val_metric'].append(au_fa_fr)\n",
        "\n",
        "#     clear_output()\n",
        "#     plt.plot(history['val_metric'])\n",
        "#     plt.ylabel('Metric')\n",
        "#     plt.xlabel('Epoch')\n",
        "#     plt.grid()\n",
        "#     plt.show()\n",
        "\n",
        "#     print('END OF EPOCH', n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI7t6qoyvv2Z",
        "outputId": "a3c18980-d578-4256-e209-083a22969d78"
      },
      "outputs": [],
      "source": [
        "validation(model, val_loader,\n",
        "                          melspec_val, config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "cUv-TiYRAfZ-"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), 'model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dHixO2dRDyAF"
      },
      "outputs": [],
      "source": [
        "# model_streaming = CRNNStreaming(config).to('cpu')\n",
        "# model_streaming.load_state_dict(torch.load('model_base.pth', map_location=torch.device('cpu')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "h8Eozd03FhTr"
      },
      "outputs": [],
      "source": [
        "# sm = torch.jit.script(model_streaming)\n",
        "# sm.save(\"model_streaming.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRZB9KXyVvfa"
      },
      "source": [
        "### Reproduce"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "ROGYjwsHR0_I"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "def distill(teacher_model, student_model, train_loader, log_melspec, epoch_number=5, alpha=0.5, temperature=2):\n",
        "    def error_and_output(var_X_batch, var_y_batch):\n",
        "        kldloss = nn.KLDivLoss()  \n",
        "        celoss = nn.CrossEntropyLoss()\n",
        "        \n",
        "        teacher_logits = teacher_model(var_X_batch)\n",
        "        student_logits = student_model(var_X_batch)\n",
        "        \n",
        "        soft_predictions = F.log_softmax( student_logits / temperature, dim=1 )\n",
        "        soft_labels = F.softmax( teacher_logits / temperature, dim=1 )\n",
        "        distillation_loss = kldloss(soft_predictions, soft_labels)\n",
        "        \n",
        "        student_loss = celoss(student_logits, var_y_batch)\n",
        "        \n",
        "        return distillation_loss * alpha + student_loss * (1 - alpha), student_logits\n",
        "    \n",
        "    optimizer = torch.optim.Adam(student_model.parameters())\n",
        "    student_model.train()\n",
        "    teacher_model.train()\n",
        "    \n",
        "    for epoch in range(epoch_number):\n",
        "        correct = 0\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
        "            X_batch = log_melspec(X_batch.to(\"cuda\"))\n",
        "            y_batch = y_batch.to(\"cuda\")\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss, output = error_and_output(X_batch, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            predicted = torch.max(output.data, 1)[1] \n",
        "            correct += (predicted == y_batch).sum()\n",
        "            if batch_idx % 200 == 0:\n",
        "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
        "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader),\\\n",
        "                     loss.data, float(correct*100) / float(128*(batch_idx+1))))\n",
        "                \n",
        "\n",
        "def error_and_output( var_X_batch, var_y_batch, teacher_model,student_model, temperature, alpha,gamma, ):\n",
        "    kldloss = nn.KLDivLoss(reduction=\"batchmean\")  \n",
        "    celoss = nn.CrossEntropyLoss()\n",
        "    \n",
        "    teacher_logits = teacher_model(var_X_batch)\n",
        "    student_logits = student_model(var_X_batch)\n",
        "    \n",
        "    soft_predictions = F.log_softmax( student_logits / temperature, dim=1 )\n",
        "    soft_labels = F.softmax( teacher_logits / temperature, dim=1 )\n",
        "    out_loss = kldloss(soft_predictions, soft_labels)\n",
        "\n",
        "    pooling1 = nn.AvgPool2d(kernel_size=4)\n",
        "    teacher_model_gru_w1 = pooling1(teacher_model.gru.weight_hh_l0.detach().unsqueeze(0)).squeeze(0)\n",
        "\n",
        "    pooling2 = nn.AvgPool2d(kernel_size=(4,1))\n",
        "    teacher_model_gru_w2 = pooling2(teacher_model.gru.weight_ih_l0.detach().unsqueeze(0)).squeeze(0)\n",
        "\n",
        "    rnn_loss1 = nn.functional.mse_loss(student_model.gru.weight_hh_l0.detach(), teacher_model_gru_w1)\n",
        "    rnn_loss2 = nn.functional.mse_loss(student_model.gru.weight_ih_l0.detach(), teacher_model_gru_w2)\n",
        "\n",
        "    pooling3 = nn.MaxPool2d(kernel_size=(4,4))\n",
        "    att_h1 = pooling3(teacher_model.attention.energy[0].weight.detach().unsqueeze(0)).squeeze(0)\n",
        "    pooling4 = nn.MaxPool2d(kernel_size=(1,4))\n",
        "    att_h2 = pooling4(teacher_model.attention.energy[2].weight.detach().unsqueeze(0)).squeeze(0)\n",
        "\n",
        "    attention_loss1 = nn.functional.mse_loss(student_model.attention.energy[0].weight.detach(), att_h1)\n",
        "    attention_loss2 = nn.functional.mse_loss(student_model.attention.energy[2].weight.detach(), att_h2)\n",
        "\n",
        "    student_loss = celoss(student_logits, var_y_batch)\n",
        "    \n",
        "    return out_loss * alpha + student_loss * (1 - alpha) + gamma*(rnn_loss1+rnn_loss2) + gamma*(attention_loss1 + attention_loss2), student_logits\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TaskConfig(keyword='sheila', batch_size=128, learning_rate=0.0004, weight_decay=1e-05, num_epochs=10, n_mels=40, cnn_out_channels=8, kernel_size=(5, 20), stride=(2, 8), hidden_size=8, gru_num_layers=1, bidirectional=False, num_classes=2, sample_rate=16000, temperature=20, alpha=0.6, gamma=0.5, device=device(type='cpu'))"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "micro_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "def distill_epoch(student_model, teacher_model, opt, loader, log_melspec, device,temperature,alpha,gamma):\n",
        "    for i, (batch, labels) in tqdm(enumerate(loader), total=len(loader)):\n",
        "        batch, labels = batch.to(device), labels.to(device)\n",
        "        batch = log_melspec(batch)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss, logits = error_and_output(batch, labels,  teacher_model,student_model, temperature, alpha, gamma,)\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "\n",
        "        opt.step()\n",
        "\n",
        "        argmax_probs = torch.argmax(probs, dim=-1)\n",
        "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
        "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
        "\n",
        "    return acc\n",
        "\n",
        "def distill(student_model, teacher_model, opt, train_loader, val_loader, melspec_train, melspec_val, config ):\n",
        "    student_model.train()\n",
        "    teacher_model.eval()\n",
        "    \n",
        "    for n in range(config.num_epochs):\n",
        "\n",
        "        distill_epoch(student_model, teacher_model, opt, train_loader,\n",
        "                    melspec_train, config.device, config.temperature, config.alpha, config.gamma)\n",
        "\n",
        "        au_fa_fr = validation(student_model, val_loader,\n",
        "                            melspec_val, config.device)\n",
        "        history['val_metric'].append(au_fa_fr)\n",
        "\n",
        "        clear_output()\n",
        "        plt.plot(history['val_metric'])\n",
        "        plt.ylabel('Metric')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "        print('END OF EPOCH', n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "micro_config = TaskConfig(\n",
        "    hidden_size=8,\n",
        "    cnn_out_channels=8,\n",
        "    gru_num_layers=1,\n",
        "    num_epochs=15,\n",
        "    temperature=20,\n",
        "    alpha=0.6,\n",
        "    gamma=0.05,\n",
        "    )\n",
        "\n",
        "student_model = CRNNmicro(micro_config).to(micro_config.device)\n",
        "\n",
        "\n",
        "base_config = TaskConfig(hidden_size=32)\n",
        "teacher_model = CRNN(base_config).to(base_config.device)\n",
        "teacher_model.load_state_dict(torch.load('checkpoints/model_base.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "optimizer = torch.optim.Adam(student_model.parameters(),\n",
        "                             lr=micro_config.learning_rate,\n",
        "                             weight_decay=micro_config.weight_decay)\n",
        "\n",
        "melspec = LogMelspec(is_train=False, config=micro_config)\n",
        "history = defaultdict(list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "END OF EPOCH 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|â–Ž         | 11/405 [00:03<02:20,  2.80it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb Cell 50\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m distill(student_model, teacher_model, optimizer, train_loader, val_loader, melspec, melspec, micro_config )\n",
            "\u001b[1;32m/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb Cell 50\u001b[0m in \u001b[0;36mdistill\u001b[0;34m(student_model, teacher_model, opt, train_loader, val_loader, melspec_train, melspec_val, config)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m teacher_model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config\u001b[39m.\u001b[39mnum_epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     distill_epoch(student_model, teacher_model, opt, train_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                 melspec_train, config\u001b[39m.\u001b[39;49mdevice, config\u001b[39m.\u001b[39;49mtemperature, config\u001b[39m.\u001b[39;49malpha, config\u001b[39m.\u001b[39;49mgamma)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     au_fa_fr \u001b[39m=\u001b[39m validation(student_model, val_loader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m                         melspec_val, config\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     history[\u001b[39m'\u001b[39m\u001b[39mval_metric\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(au_fa_fr)\n",
            "\u001b[1;32m/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb Cell 50\u001b[0m in \u001b[0;36mdistill_epoch\u001b[0;34m(student_model, teacher_model, opt, loader, log_melspec, device, temperature, alpha, gamma)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (batch, labels) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(loader), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(loader)):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     batch, labels \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     batch \u001b[39m=\u001b[39m log_melspec(batch)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     loss, logits \u001b[39m=\u001b[39m error_and_output(batch, labels,  teacher_model,student_model, temperature, alpha, gamma,)\n",
            "\u001b[1;32m/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb Cell 50\u001b[0m in \u001b[0;36mLogMelspec.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# already on device\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mikhailoleynik/Desktop/hse-dla/kws/main.ipynb#Y136sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmelspec(batch)\u001b[39m.\u001b[39mclamp_(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1e-9\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1e9\u001b[39m))\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchaudio/transforms/_transforms.py:616\u001b[0m, in \u001b[0;36mMelSpectrogram.forward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, waveform: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    609\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    611\u001b[0m \u001b[39m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[39m        Tensor: Mel frequency spectrogram of size (..., ``n_mels``, time).\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     specgram \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspectrogram(waveform)\n\u001b[1;32m    617\u001b[0m     mel_specgram \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmel_scale(specgram)\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m mel_specgram\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchaudio/transforms/_transforms.py:106\u001b[0m, in \u001b[0;36mSpectrogram.forward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, waveform: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     97\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m        Fourier bins, and time is the number of window hops (n_frame).\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mspectrogram(\n\u001b[1;32m    107\u001b[0m         waveform,\n\u001b[1;32m    108\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad,\n\u001b[1;32m    109\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindow,\n\u001b[1;32m    110\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_fft,\n\u001b[1;32m    111\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhop_length,\n\u001b[1;32m    112\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwin_length,\n\u001b[1;32m    113\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpower,\n\u001b[1;32m    114\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized,\n\u001b[1;32m    115\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcenter,\n\u001b[1;32m    116\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_mode,\n\u001b[1;32m    117\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49monesided,\n\u001b[1;32m    118\u001b[0m     )\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torchaudio/functional/functional.py:133\u001b[0m, in \u001b[0;36mspectrogram\u001b[0;34m(waveform, pad, window, n_fft, hop_length, win_length, power, normalized, center, pad_mode, onesided, return_complex)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39mif\u001b[39;00m power \u001b[39m==\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m    132\u001b[0m         \u001b[39mreturn\u001b[39;00m spec_f\u001b[39m.\u001b[39mabs()\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mreturn\u001b[39;00m spec_f\u001b[39m.\u001b[39;49mabs()\u001b[39m.\u001b[39;49mpow(power)\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m spec_f\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "distill(student_model, teacher_model, optimizer, train_loader, val_loader, melspec, melspec, micro_config )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8yJLvAmR1GB",
        "outputId": "41009665-7235-42e1-896b-beb3c24341ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 0 [0/51776 (0%)]\tLoss: 0.225273\t Accuracy:50.000%\n",
            "Epoch : 0 [25600/51776 (49%)]\tLoss: 0.085386\t Accuracy:88.099%\n",
            "Epoch : 0 [51200/51776 (99%)]\tLoss: 0.052793\t Accuracy:91.313%\n",
            "Epoch : 1 [0/51776 (0%)]\tLoss: 0.056604\t Accuracy:96.875%\n",
            "Epoch : 1 [25600/51776 (49%)]\tLoss: 0.064278\t Accuracy:95.281%\n",
            "Epoch : 1 [51200/51776 (99%)]\tLoss: 0.055870\t Accuracy:95.749%\n",
            "Epoch : 2 [0/51776 (0%)]\tLoss: 0.056073\t Accuracy:97.656%\n",
            "Epoch : 2 [25600/51776 (49%)]\tLoss: 0.056486\t Accuracy:96.105%\n",
            "Epoch : 2 [51200/51776 (99%)]\tLoss: 0.065301\t Accuracy:96.337%\n",
            "Epoch : 3 [0/51776 (0%)]\tLoss: 0.057205\t Accuracy:96.875%\n",
            "Epoch : 3 [25600/51776 (49%)]\tLoss: 0.057141\t Accuracy:96.875%\n",
            "Epoch : 3 [51200/51776 (99%)]\tLoss: 0.064901\t Accuracy:97.025%\n",
            "Epoch : 4 [0/51776 (0%)]\tLoss: 0.057685\t Accuracy:99.219%\n",
            "Epoch : 4 [25600/51776 (49%)]\tLoss: 0.084014\t Accuracy:97.295%\n",
            "Epoch : 4 [51200/51776 (99%)]\tLoss: 0.070976\t Accuracy:97.237%\n",
            "Epoch : 5 [0/51776 (0%)]\tLoss: 0.062046\t Accuracy:98.438%\n",
            "Epoch : 5 [25600/51776 (49%)]\tLoss: 0.085814\t Accuracy:97.287%\n",
            "Epoch : 5 [51200/51776 (99%)]\tLoss: 0.060940\t Accuracy:97.265%\n",
            "Epoch : 6 [0/51776 (0%)]\tLoss: 0.063692\t Accuracy:97.656%\n",
            "Epoch : 6 [25600/51776 (49%)]\tLoss: 0.066029\t Accuracy:97.415%\n",
            "Epoch : 6 [51200/51776 (99%)]\tLoss: 0.064408\t Accuracy:97.428%\n",
            "Epoch : 7 [0/51776 (0%)]\tLoss: 0.060163\t Accuracy:100.000%\n",
            "Epoch : 7 [25600/51776 (49%)]\tLoss: 0.081115\t Accuracy:97.617%\n",
            "Epoch : 7 [51200/51776 (99%)]\tLoss: 0.068843\t Accuracy:97.674%\n",
            "Epoch : 8 [0/51776 (0%)]\tLoss: 0.077613\t Accuracy:95.312%\n",
            "Epoch : 8 [25600/51776 (49%)]\tLoss: 0.077169\t Accuracy:97.823%\n",
            "Epoch : 8 [51200/51776 (99%)]\tLoss: 0.077410\t Accuracy:97.668%\n",
            "Epoch : 9 [0/51776 (0%)]\tLoss: 0.084622\t Accuracy:95.312%\n",
            "Epoch : 9 [25600/51776 (49%)]\tLoss: 0.065606\t Accuracy:97.987%\n",
            "Epoch : 9 [51200/51776 (99%)]\tLoss: 0.068340\t Accuracy:97.995%\n",
            "Epoch : 10 [0/51776 (0%)]\tLoss: 0.088974\t Accuracy:96.875%\n",
            "Epoch : 10 [25600/51776 (49%)]\tLoss: 0.064494\t Accuracy:97.819%\n",
            "Epoch : 10 [51200/51776 (99%)]\tLoss: 0.079481\t Accuracy:97.822%\n",
            "Epoch : 11 [0/51776 (0%)]\tLoss: 0.071774\t Accuracy:97.656%\n",
            "Epoch : 11 [25600/51776 (49%)]\tLoss: 0.066965\t Accuracy:97.816%\n",
            "Epoch : 11 [51200/51776 (99%)]\tLoss: 0.080108\t Accuracy:97.835%\n",
            "Epoch : 12 [0/51776 (0%)]\tLoss: 0.073519\t Accuracy:98.438%\n",
            "Epoch : 12 [25600/51776 (49%)]\tLoss: 0.077019\t Accuracy:97.913%\n",
            "Epoch : 12 [51200/51776 (99%)]\tLoss: 0.075044\t Accuracy:98.024%\n",
            "Epoch : 13 [0/51776 (0%)]\tLoss: 0.069272\t Accuracy:100.000%\n",
            "Epoch : 13 [25600/51776 (49%)]\tLoss: 0.068139\t Accuracy:97.994%\n",
            "Epoch : 13 [51200/51776 (99%)]\tLoss: 0.074547\t Accuracy:97.896%\n",
            "Epoch : 14 [0/51776 (0%)]\tLoss: 0.082367\t Accuracy:98.438%\n",
            "Epoch : 14 [25600/51776 (49%)]\tLoss: 0.070587\t Accuracy:98.092%\n",
            "Epoch : 14 [51200/51776 (99%)]\tLoss: 0.074309\t Accuracy:98.058%\n"
          ]
        }
      ],
      "source": [
        "#distill_layerwise(model.to('cuda'), student_model, train_loader,log_melspec=melspec_val, epoch_number=15, alpha=0.65,gamma=0.05, temperature=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSEDyE15R1Lq",
        "outputId": "9266f72e-27a9-44e8-ac7d-8e70455348bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "102it [00:05, 18.17it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6.482546937372527e-05"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation(student_model, val_loader,\n",
        "                          melspec_val, config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t55FUkOGh9pT",
        "outputId": "a68cbb5b-bb48-4834-d57f-a4069841a8c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CRNNmicro(\n",
            "  (dsconv): Sequential(\n",
            "    (0): DSConv2d(\n",
            "      (depthwise): Conv2d(1, 1, kernel_size=(5, 20), stride=(2, 8))\n",
            "      (pointwise): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (1): Flatten(start_dim=1, end_dim=2)\n",
            "  )\n",
            "  (gru): DynamicQuantizedGRU(144, 8, batch_first=True, dropout=0.1)\n",
            "  (attention): Attention(\n",
            "    (energy): Sequential(\n",
            "      (0): DynamicQuantizedLinear(in_features=8, out_features=8, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
            "      (1): Tanh()\n",
            "      (2): DynamicQuantizedLinear(in_features=8, out_features=1, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
            "    )\n",
            "  )\n",
            "  (classifier): DynamicQuantizedLinear(in_features=8, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# config = TaskConfig(hidden_size=16)\n",
        "# model = CRNN(config).to(config.device)\n",
        "\n",
        "# here we specify weights data format and layers that are to be quantized\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    student_model.to(\"cpu\"), {torch.nn.Linear, torch.nn.Conv2d, torch.nn.GRU, \"dsconv.0.depthwise\",\"dsconv.0.pointwise\" }, dtype=torch.torch.qint8\n",
        ")\n",
        "print(quantized_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw9V0GSWnmKy",
        "outputId": "b9b492cc-2314-446f-e06d-aff0e9805cd0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "102it [00:09, 11.22it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "6.659783100531842e-05"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_config = TaskConfig(device='cpu')\n",
        "\n",
        "melspec_test = LogMelspec(is_train=False, config=test_config)\n",
        "validation(quantized_model.to('cpu'), val_loader,\n",
        "                          melspec_test, test_config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaEINyDLNo0_",
        "outputId": "4046189e-f0c3-4895-828d-f5304a7c4aea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "102it [00:08, 11.81it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0001732319387323825"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pruned_model = model\n",
        "# pruned_model.prune(rate=0.7)\n",
        "# test_config = TaskConfig(device='cpu')\n",
        "\n",
        "# melspec_test = LogMelspec(is_train=False, config=test_config)\n",
        "# validation(pruned_model.to('cpu'), val_loader,\n",
        "#                           melspec_test, test_config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMyMzU5QBzCr",
        "outputId": "42d18765-42a6-4ee1-d835-1d24a0254d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n"
          ]
        }
      ],
      "source": [
        "from thop import profile  # !pip install thop\n",
        "from thop import clever_format\n",
        "\n",
        "# batch, label = next(iter(train_loader))\n",
        "sample = torch.randn(1, 40, 101).to('cpu')#.unsqueeze(0)\n",
        "base = profile(model.to('cpu'), (sample,))\n",
        "distilled = profile(student_model.to('cpu'), (sample,))\n",
        "distilled_quantized = profile(quantized_model.to('cpu'), (sample,))   # -> (6.0 MACs, 3.0 parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwqMoi3J8e5P",
        "outputId": "b9be9119-ef4a-4ba9-ace6-6776904b5466"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(432672.0, 63464.0, 21384.0, 6.817597378041095, 20.2334455667789)"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base[0], distilled[0], distilled_quantized[0], base[0]/distilled[0], base[0]/distilled_quantized[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L18tcGI9UUV",
        "outputId": "ad72b931-5e61-44cf-ed60-bc36fd065370"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.10348224639892578,\n",
              " 0.02163410186767578,\n",
              " 0.01869678497314453,\n",
              " 5.534761540423362)"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base = get_size_in_megabytes(model)\n",
        "distilled = get_size_in_megabytes(student_model)\n",
        "distilled_quantized = get_size_in_megabytes(quantized_model)\n",
        "base, distilled, distilled_quantized,  base / distilled_quantized"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.11 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
